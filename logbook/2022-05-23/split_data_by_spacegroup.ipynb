{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Group data by space group\n",
            "\n",
            "Notebook for splitting CSD dataset by spacegroup, tokenizing the files, and writing the weighted training yaml files."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Tokenize SMILES"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "import re\n",
            "import pandas as pd \n",
            "from pathlib import Path\n",
            "\n",
            "data_dir = f'{str(Path(Path.cwd()).parents[1])}/data'\n",
            "df_organic = pd.read_csv(f\"{data_dir}/csd_organic_tokenized.csv\")\n",
            "df_organic = df_organic.dropna()\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>id</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>VUCKIQ</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>JUTSUM</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>RAVBEV</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>DUTQAN</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>TUBVUJ</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>269465</th>\n",
                     "      <td>AQIPAU</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>269466</th>\n",
                     "      <td>IMIFER</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>269467</th>\n",
                     "      <td>HEXYIV</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>269468</th>\n",
                     "      <td>RAGPAQ</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>269469</th>\n",
                     "      <td>VILVEU</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>269470 rows Ã— 1 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "            id\n",
                     "0       VUCKIQ\n",
                     "1       JUTSUM\n",
                     "2       RAVBEV\n",
                     "3       DUTQAN\n",
                     "4       TUBVUJ\n",
                     "...        ...\n",
                     "269465  AQIPAU\n",
                     "269466  IMIFER\n",
                     "269467  HEXYIV\n",
                     "269468  RAGPAQ\n",
                     "269469  VILVEU\n",
                     "\n",
                     "[269470 rows x 1 columns]"
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "dataset_name = 'smi2spgnum'\n",
            "df_train_ids = pd.read_csv(f\"{data_dir}/{dataset_name}/id-train.csv\", header=None, names=['id'])\n",
            "df_valid_ids = pd.read_csv(f\"{data_dir}/{dataset_name}/id-valid.csv\", header=None, names=['id'])\n",
            "\n",
            "df_train_ids"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_train = df_organic.query('identifier in @df_train_ids.id')\n",
            "df_valid = df_organic.query('identifier in @df_valid_ids.id')\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "from smi2wyk.transformer_utils import write_train_val_test, submit_training_job, write_tokenized_dataframe"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "train\n",
                  "valid\n"
               ]
            }
         ],
         "source": [
            "import os\n",
            "common_spacegroups = [14, 19, 4, 2, 61, 33]\n",
            "\n",
            "for df, index in zip([df_train, df_valid], ['train', 'valid']):\n",
            "    print(index)\n",
            "    df_common = df.query('spg_num in @common_spacegroups')\n",
            "    df_uncommon = df.query('spg_num not in @common_spacegroups')\n",
            "\n",
            "    data_dir = str(Path(os.getcwd()).parents[1])+'/data'\n",
            "    \n",
            "    data_path = f'{data_dir}/{dataset_name}'\n",
            "    \n",
            "    write_tokenized_dataframe(df_common, data_path=f\"{data_path}/common\", index=index, tgt_col = 'spg_num')\n",
            "    write_tokenized_dataframe(df_uncommon, data_path=f\"{data_path}/uncommon\", index=index, tgt_col = 'spg_num')\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "from smi2wyk.transformer_utils import write_preprocess_yaml, write_training_yaml\n",
            "\n",
            "data_dir = str(Path(os.getcwd()).parents[1])+'/data'\n",
            "    \n",
            "data_path = f'{data_dir}/{dataset_name}'\n",
            "write_preprocess_yaml(data_path,\n",
            "                        share_vocab = False, \n",
            "                        weighted_sampling = True,\n",
            "                        weight_folder_names = ['common', 'uncommon'], \n",
            "                        weights = [1,1])\n",
            "write_training_yaml(data_path, \n",
            "                    dataset_name = dataset_name, \n",
            "                    share_vocab=False, \n",
            "                    n_gpu = 1)\n",
            "write_training_yaml(data_path, \n",
            "                    dataset_name = dataset_name, \n",
            "                    share_vocab=False, \n",
            "                    weighted_sampling=True, \n",
            "                    weight_folder_names = ['common', 'uncommon'], \n",
            "                    weights = [1,1],\n",
            "                    n_gpu = 1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Submitted batch job 61633933\n"
               ]
            }
         ],
         "source": [
            "!sbatch subm_train_smi2spgnum"
         ]
      }
   ],
   "metadata": {
      "interpreter": {
         "hash": "4a98ec2822b38b1948661d4c5686e8b34cc301e9c46a1188b0127b15dc9e9c3f"
      },
      "kernelspec": {
         "display_name": "Python 3.7.13 64-bit ('csd_env')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.7.13"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
