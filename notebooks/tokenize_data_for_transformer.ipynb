{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Tokenize data\n",
            "\n",
            "Notebook for performing tokenization of the SMILES strings as well as target values of interest"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Tokenize SMILES"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 361607/361607 [00:06<00:00, 57628.20it/s]\n"
               ]
            }
         ],
         "source": [
            "import re\n",
            "import pandas as pd\n",
            "from tqdm import tqdm\n",
            "\n",
            "def tokenize_smiles(smi):\n",
            "    \"\"\"\n",
            "    Tokenize a SMILES molecule or reaction \n",
            "    \"\"\"\n",
            "    pattern = \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
            "\n",
            "    regex = re.compile(pattern)\n",
            "    tokens = [token for token in regex.findall(smi)]\n",
            "    smi_tokenized = ' '.join(tokens)\n",
            "    return smi_tokenized\n",
            "\n",
            "df_organic = pd.read_csv(\"csd_organic.csv\")\n",
            "df_organic = df_organic.dropna()\n",
            "\n",
            "tqdm.pandas()\n",
            "df_organic['smi_tokenized'] = df_organic['smiles'].progress_apply(tokenize_smiles)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Only prototype & pearson symbol"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic['tgt'] = df_organic['prototype'] + ': ' + df_organic['pearson']\n",
            "df_organic['tgt'] = [re.sub('([A-Z]):', r'\\1 :', tgt) for tgt in df_organic['tgt']]\n",
            "df_organic"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Only the spacegroup number"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 361607/361607 [22:48<00:00, 264.23it/s] \n"
               ]
            }
         ],
         "source": [
            "from ccdc import io\n",
            "\n",
            "def spacegroup_num_and_str_from_crystal(row, reader: io.EntryReader = None):\n",
            "    \n",
            "    if reader is None:\n",
            "        reader = io.EntryReader()\n",
            "\n",
            "    csd_entry = row['identifier']\n",
            "    entry = reader.entry(csd_entry)\n",
            "    crystal = entry.crystal\n",
            "    try:\n",
            "        spg_num = crystal.spacegroup_number_and_setting[0]\n",
            "        spg_str= crystal.spacegroup_symbol\n",
            "        row['spg_num'] = spg_num\n",
            "        row['spg_str'] = spg_str\n",
            "    except:\n",
            "        row['spg_num'] = None\n",
            "        row['spg_str'] = None\n",
            "    return row\n",
            "\n",
            "def spacegroup_str_from_crystal(csd_entry: str, reader: io.EntryReader = None):\n",
            "    \n",
            "    if reader is None:\n",
            "        reader = io.EntryReader()\n",
            "\n",
            "    entry = reader.entry(csd_entry)\n",
            "    crystal = entry.crystal\n",
            "    spg = crystal.spacegroup_symbol\n",
            "    return spg\n",
            "\n",
            "csd_reader = io.EntryReader()\n",
            "# df_head = df_organic.head().copy()\n",
            "# df_head.progress_apply(spacegroup_num_and_str_from_crystal, reader=csd_reader, axis=1)\n",
            "# df_organic['spg_num'] = df_organic['identifier'].progress_apply(spacegroup_num_from_crystal, reader=csd_reader)\n",
            "# df_organic['spg_str'] = df_organic['identifier'].progress_apply(spacegroup_str_from_crystal, reader=csd_reader)\n",
            "df_organic = df_organic.progress_apply(spacegroup_num_and_str_from_crystal, reader=csd_reader, axis=1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "identifier       0\n",
                     "smiles           0\n",
                     "wyckoff          0\n",
                     "smi_tokenized    0\n",
                     "spg_num          1\n",
                     "spg_str          1\n",
                     "dtype: int64"
                  ]
               },
               "execution_count": 19,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df_organic.isna().sum()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic = df_organic.dropna()\n",
            "df_organic.spg_num = df_organic.spg_num.astype(int)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic.dropna().to_csv(\"csd_organic_tokenized.csv\", index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'Pb21a'"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "csd_reader = io.EntryReader()\n",
            "\n",
            "entry = csd_reader.entry('MTYHFB03')\n",
            "crystal = entry.crystal\n",
            "crystal.spacegroup_symbol"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic.to_csv(\"csd_organic_tokenized.csv\", index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os \n",
            "import yaml\n",
            "from pathlib import Path\n",
            "\n",
            "\n",
            "def write_default_preprocess_yaml(data_path):\n",
            "    preprocess_file_name = f'{data_path}/preprocess.yaml'\n",
            "    \n",
            "    preprocess_dict = dict(\n",
            "        save_data = f'{data_path}',\n",
            "        src_vocab = f'{data_path}/vocab.src',\n",
            "        tgt_vocab = f'{data_path}/vocab.tgt',\n",
            "        overwrite = True,\n",
            "        n_sample = -1,\n",
            "        share_vocab = False,\n",
            "        data = dict(\n",
            "            train = dict(\n",
            "                path_src = f'{data_path}/src-train.csv',\n",
            "                path_tgt = f'{data_path}/tgt-train.csv',\n",
            "            ),\n",
            "            valid = dict(\n",
            "                path_src = f'{data_path}/src-valid.csv',\n",
            "                path_tgt = f'{data_path}/tgt-valid.csv',\n",
            "            )\n",
            "        )\n",
            "    )\n",
            "    \n",
            "    with open(preprocess_file_name, 'w') as f:\n",
            "        yaml.dump(preprocess_dict, f)\n",
            "    return\n",
            "\n",
            "def write_default_training_yaml(data_path, dataset_name):\n",
            "    training_file_name = f'{data_path}/train_single.yaml'\n",
            "    \n",
            "    training_dict = dict(\n",
            "        save_data = f'{data_path}',\n",
            "        src_vocab = f'{data_path}/vocab.src',\n",
            "        tgt_vocab = f'{data_path}/vocab.tgt',\n",
            "\n",
            "        share_vocab = False,\n",
            "        data = dict(\n",
            "            train = dict(\n",
            "                path_src = f'{data_path}/src-train.csv',\n",
            "                path_tgt = f'{data_path}/tgt-train.csv',\n",
            "            ),\n",
            "            valid = dict(\n",
            "                path_src = f'{data_path}/src-valid.csv',\n",
            "                path_tgt = f'{data_path}/tgt-valid.csv',\n",
            "            )\n",
            "        ),\n",
            "        \n",
            "        save_model = f'/rds-d2/user/wjm41/hpc-work/models/smi2wyk/{dataset_name}/model',\n",
            "        save_checkpoint_steps = 2500,\n",
            "        keep_checkpoint = 2,\n",
            "        seed = 42,\n",
            "        train_steps = 500000,\n",
            "        valid_steps = 5000,\n",
            "        warmup_steps = 8000,\n",
            "        report_every = 1000,\n",
            "        \n",
            "        decoder_type = 'transformer',\n",
            "        encoder_type = 'transformer',\n",
            "        word_vec_size = 256,\n",
            "        rnn_size = 256, \n",
            "        layers = 4,\n",
            "        transformer_ff = 2048,\n",
            "        heads = 8,\n",
            "        global_attention = 'general',\n",
            "        global_attention_function = 'softmax',\n",
            "        self_attn_type = 'scaled-dot',\n",
            "        \n",
            "        accum_count = 4,\n",
            "        optim = 'adam',\n",
            "        adam_beta1 = 0.9,\n",
            "        adam_beta2 = 0.998,\n",
            "        decay_method = 'noam',\n",
            "        learning_rate = 2.0,\n",
            "        max_grad_norm = 0.0,\n",
            "\n",
            "        batch_size = 1024,\n",
            "        batch_type = 'tokens',\n",
            "        normalization = 'tokens',\n",
            "        dropout = 0.1,\n",
            "        label_smoothing = 0.0,\n",
            "\n",
            "        max_generator_batches = 32,\n",
            "\n",
            "        param_init = 0.0,\n",
            "        param_init_glorot = 'true',\n",
            "        position_encoding = 'true',\n",
            "\n",
            "        world_size = 1,\n",
            "        gpu_ranks = [0],\n",
            "    )\n",
            "    \n",
            "    with open(training_file_name, 'w') as f:\n",
            "        yaml.dump(training_dict, f)\n",
            "    return\n",
            "\n",
            "def write_train_val_test(df, dataset_name, tgt_col: str = 'tgt'):\n",
            "\n",
            "    df = df.drop_duplicates(subset=['smiles'])\n",
            "    df_train_and_val = df.sample(frac=0.9, random_state=42)\n",
            "    df_test = df.drop(df_train_and_val.index)\n",
            "\n",
            "    df_train = df_train_and_val.sample(frac=0.9, random_state=42)\n",
            "    df_valid = df_train_and_val.drop(df_train.index)\n",
            "\n",
            "    data_dir = str(Path(os.getcwd()).parents[0])+'/data'\n",
            "    \n",
            "    data_path = f'{data_dir}/{dataset_name}'\n",
            "    Path(data_path).mkdir(parents=True, exist_ok=True)\n",
            "    df_train.smi_tokenized.to_csv(f'{data_path}/src-train.csv', index=False, header=False)\n",
            "    df_train.identifier.to_csv(f'{data_path}/id-train.csv', index=False, header=False)\n",
            "    df_train[tgt_col].to_csv(f'{data_path}/tgt-train.csv', index=False, header=False)\n",
            "\n",
            "    df_valid.smi_tokenized.to_csv(f'{data_path}/src-valid.csv', index=False, header=False)\n",
            "    df_valid.identifier.to_csv(f'{data_path}/id-valid.csv', index=False, header=False)\n",
            "    df_valid[tgt_col].to_csv(f'{data_path}/tgt-valid.csv', index=False, header=False)\n",
            "\n",
            "    df_test.smi_tokenized.to_csv(f'{data_path}/src-test.csv', index=False, header=False)\n",
            "    df_test.identifier.to_csv(f'{data_path}/id-test.csv', index=False, header=False)\n",
            "    df_test[tgt_col].to_csv(f'{data_path}/tgt-test.csv', index=False, header=False)\n",
            "    \n",
            "    write_default_preprocess_yaml(data_path)\n",
            "    write_default_training_yaml(data_path, dataset_name = dataset_name)\n",
            "    return"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>identifier</th>\n",
                     "      <th>smiles</th>\n",
                     "      <th>wyckoff</th>\n",
                     "      <th>smi_tokenized</th>\n",
                     "      <th>spg_num</th>\n",
                     "      <th>spg_str</th>\n",
                     "      <th>spg_str_tokenized</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>AABHTZ</td>\n",
                     "      <td>CC(=O)NN1C=NN=C1N(N=Cc1c(Cl)cccc1Cl)C(C)=O</td>\n",
                     "      <td>A13B2C12D6E2_aP70_2_13i_2i_12i_6i_2i:C-Cl-H-N-O</td>\n",
                     "      <td>C C ( = O ) N N 1 C = N N = C 1 N ( N = C c 1 ...</td>\n",
                     "      <td>2</td>\n",
                     "      <td>P-1</td>\n",
                     "      <td>P - 1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>AACFAZ10</td>\n",
                     "      <td>COC1=C(C(OC1=O)c1ccccc1Cl)C(C)=NN=C(C)C1=C(OC)...</td>\n",
                     "      <td>A13BC11DE3_oP232_60_13d_d_11d_d_3d:C-Cl-H-N-O</td>\n",
                     "      <td>C O C 1 = C ( C ( O C 1 = O ) c 1 c c c c c 1 ...</td>\n",
                     "      <td>60</td>\n",
                     "      <td>Pbcn</td>\n",
                     "      <td>P b c n</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>AACMHX10</td>\n",
                     "      <td>CC(=O)OC(=C1CCCCC1c1ccccc1)c1ccccc1</td>\n",
                     "      <td>A21B22C2_oP360_61_21c_22c_2c:C-H-O</td>\n",
                     "      <td>C C ( = O ) O C ( = C 1 C C C C C 1 c 1 c c c ...</td>\n",
                     "      <td>61</td>\n",
                     "      <td>Pbca</td>\n",
                     "      <td>P b c a</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>AADAMC</td>\n",
                     "      <td>[Br-].[NH3+]C1(C2CC3CC(C2)CC1C3)C(O)=O</td>\n",
                     "      <td>AB11C18DE2_mP132_14_e_11e_18e_e_2e:Br-C-H-N-O</td>\n",
                     "      <td>[Br-] . [NH3+] C 1 ( C 2 C C 3 C C ( C 2 ) C C...</td>\n",
                     "      <td>14</td>\n",
                     "      <td>P21/c</td>\n",
                     "      <td>P 2 1 / c</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>AADMPY10</td>\n",
                     "      <td>Cc1[nH+]c(N)nc(N)c1C12CC3CC(CC(C3)C1)C2.CCS(=O...</td>\n",
                     "      <td>A17B28C4D3E_aP106_2_17i_28i_4i_3i_i:C-H-N-O-S</td>\n",
                     "      <td>C c 1 [nH+] c ( N ) n c ( N ) c 1 C 1 2 C C 3 ...</td>\n",
                     "      <td>2</td>\n",
                     "      <td>P-1</td>\n",
                     "      <td>P - 1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>361601</th>\n",
                     "      <td>ZUWRIS01</td>\n",
                     "      <td>Oc1ccccc1C=NNS(=O)(=O)c1ccccc1</td>\n",
                     "      <td>A13B12C2D3E_mP124_14_13e_12e_2e_3e_e:C-H-N-O-S</td>\n",
                     "      <td>O c 1 c c c c c 1 C = N N S ( = O ) ( = O ) c ...</td>\n",
                     "      <td>14</td>\n",
                     "      <td>P21/c</td>\n",
                     "      <td>P 2 1 / c</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>361602</th>\n",
                     "      <td>ZZZDTW01</td>\n",
                     "      <td>OC(=O)CC(O)(CC(O)=O)C(=O)[O-].[NH4+]</td>\n",
                     "      <td>A6B11CD7_aP50_2_6i_ac10i_i_7i:C-H-N-O</td>\n",
                     "      <td>O C ( = O ) C C ( O ) ( C C ( O ) = O ) C ( = ...</td>\n",
                     "      <td>2</td>\n",
                     "      <td>P-1</td>\n",
                     "      <td>P - 1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>361603</th>\n",
                     "      <td>ZZZJCQ04</td>\n",
                     "      <td>c1ccc(cc1)N(c1ccccc1)c1ccccc1.c1ccc(cc1)N(c1cc...</td>\n",
                     "      <td>A18B15C_mC544_9_72a_60a_4a:C-H-N</td>\n",
                     "      <td>c 1 c c c ( c c 1 ) N ( c 1 c c c c c 1 ) c 1 ...</td>\n",
                     "      <td>9</td>\n",
                     "      <td>Cc</td>\n",
                     "      <td>C c</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>361604</th>\n",
                     "      <td>ZZZPTQ01</td>\n",
                     "      <td>[NH3+]CC(=O)NCC(=O)NCC(=O)[O-].O.O</td>\n",
                     "      <td>A2B5CD2_oP120_29_6a_15a_3a_6a:C-H-N-O</td>\n",
                     "      <td>[NH3+] C C ( = O ) N C C ( = O ) N C C ( = O )...</td>\n",
                     "      <td>29</td>\n",
                     "      <td>Pca21</td>\n",
                     "      <td>P c a 2 1</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>361605</th>\n",
                     "      <td>ZZZSEA03</td>\n",
                     "      <td>OC1COC(O)C(O)C1O</td>\n",
                     "      <td>AB2C_oP80_19_5a_10a_5a:C-H-O</td>\n",
                     "      <td>O C 1 C O C ( O ) C ( O ) C 1 O</td>\n",
                     "      <td>19</td>\n",
                     "      <td>P212121</td>\n",
                     "      <td>P 2 1 2 1 2 1</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>361606 rows × 7 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "       identifier                                             smiles  \\\n",
                     "0          AABHTZ         CC(=O)NN1C=NN=C1N(N=Cc1c(Cl)cccc1Cl)C(C)=O   \n",
                     "1        AACFAZ10  COC1=C(C(OC1=O)c1ccccc1Cl)C(C)=NN=C(C)C1=C(OC)...   \n",
                     "2        AACMHX10                CC(=O)OC(=C1CCCCC1c1ccccc1)c1ccccc1   \n",
                     "3          AADAMC             [Br-].[NH3+]C1(C2CC3CC(C2)CC1C3)C(O)=O   \n",
                     "4        AADMPY10  Cc1[nH+]c(N)nc(N)c1C12CC3CC(CC(C3)C1)C2.CCS(=O...   \n",
                     "...           ...                                                ...   \n",
                     "361601   ZUWRIS01                     Oc1ccccc1C=NNS(=O)(=O)c1ccccc1   \n",
                     "361602   ZZZDTW01               OC(=O)CC(O)(CC(O)=O)C(=O)[O-].[NH4+]   \n",
                     "361603   ZZZJCQ04  c1ccc(cc1)N(c1ccccc1)c1ccccc1.c1ccc(cc1)N(c1cc...   \n",
                     "361604   ZZZPTQ01                 [NH3+]CC(=O)NCC(=O)NCC(=O)[O-].O.O   \n",
                     "361605   ZZZSEA03                                   OC1COC(O)C(O)C1O   \n",
                     "\n",
                     "                                                wyckoff  \\\n",
                     "0       A13B2C12D6E2_aP70_2_13i_2i_12i_6i_2i:C-Cl-H-N-O   \n",
                     "1         A13BC11DE3_oP232_60_13d_d_11d_d_3d:C-Cl-H-N-O   \n",
                     "2                    A21B22C2_oP360_61_21c_22c_2c:C-H-O   \n",
                     "3         AB11C18DE2_mP132_14_e_11e_18e_e_2e:Br-C-H-N-O   \n",
                     "4         A17B28C4D3E_aP106_2_17i_28i_4i_3i_i:C-H-N-O-S   \n",
                     "...                                                 ...   \n",
                     "361601   A13B12C2D3E_mP124_14_13e_12e_2e_3e_e:C-H-N-O-S   \n",
                     "361602            A6B11CD7_aP50_2_6i_ac10i_i_7i:C-H-N-O   \n",
                     "361603                 A18B15C_mC544_9_72a_60a_4a:C-H-N   \n",
                     "361604            A2B5CD2_oP120_29_6a_15a_3a_6a:C-H-N-O   \n",
                     "361605                     AB2C_oP80_19_5a_10a_5a:C-H-O   \n",
                     "\n",
                     "                                            smi_tokenized  spg_num  spg_str  \\\n",
                     "0       C C ( = O ) N N 1 C = N N = C 1 N ( N = C c 1 ...        2      P-1   \n",
                     "1       C O C 1 = C ( C ( O C 1 = O ) c 1 c c c c c 1 ...       60     Pbcn   \n",
                     "2       C C ( = O ) O C ( = C 1 C C C C C 1 c 1 c c c ...       61     Pbca   \n",
                     "3       [Br-] . [NH3+] C 1 ( C 2 C C 3 C C ( C 2 ) C C...       14    P21/c   \n",
                     "4       C c 1 [nH+] c ( N ) n c ( N ) c 1 C 1 2 C C 3 ...        2      P-1   \n",
                     "...                                                   ...      ...      ...   \n",
                     "361601  O c 1 c c c c c 1 C = N N S ( = O ) ( = O ) c ...       14    P21/c   \n",
                     "361602  O C ( = O ) C C ( O ) ( C C ( O ) = O ) C ( = ...        2      P-1   \n",
                     "361603  c 1 c c c ( c c 1 ) N ( c 1 c c c c c 1 ) c 1 ...        9       Cc   \n",
                     "361604  [NH3+] C C ( = O ) N C C ( = O ) N C C ( = O )...       29    Pca21   \n",
                     "361605                    O C 1 C O C ( O ) C ( O ) C 1 O       19  P212121   \n",
                     "\n",
                     "       spg_str_tokenized  \n",
                     "0                  P - 1  \n",
                     "1                P b c n  \n",
                     "2                P b c a  \n",
                     "3              P 2 1 / c  \n",
                     "4                  P - 1  \n",
                     "...                  ...  \n",
                     "361601         P 2 1 / c  \n",
                     "361602             P - 1  \n",
                     "361603               C c  \n",
                     "361604         P c a 2 1  \n",
                     "361605     P 2 1 2 1 2 1  \n",
                     "\n",
                     "[361606 rows x 7 columns]"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import pandas as pd\n",
            "\n",
            "df_organic = pd.read_csv('csd_organic_tokenized.csv')\n",
            "df_organic['spg_str_tokenized'] = [' '.join(list(spg_str)) for spg_str in df_organic['spg_str']]\n",
            "df_organic"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "write_train_val_test(df_organic, dataset_name='smi2spgnum', tgt_col='spg_num')\n",
            "write_train_val_test(df_organic, dataset_name='smi2spgstr', tgt_col='spg_str')\n",
            "write_train_val_test(df_organic, dataset_name='smi2spgstrtok', tgt_col='spg_str_tokenized')\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "interpreter": {
         "hash": "4a98ec2822b38b1948661d4c5686e8b34cc301e9c46a1188b0127b15dc9e9c3f"
      },
      "kernelspec": {
         "display_name": "Python 3.7.13 64-bit ('csd_env')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.7.13"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
