{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Tokenize data\n",
            "\n",
            "Notebook for performing tokenization of the SMILES strings as well as target values of interest"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Tokenize SMILES"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 361607/361607 [00:06<00:00, 57628.20it/s]\n"
               ]
            }
         ],
         "source": [
            "import re\n",
            "import pandas as pd\n",
            "from tqdm import tqdm\n",
            "\n",
            "def tokenize_smiles(smi):\n",
            "    \"\"\"\n",
            "    Tokenize a SMILES molecule or reaction \n",
            "    \"\"\"\n",
            "    pattern = \"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|-|\\+|\\\\\\\\|\\/|:|~|@|\\?|>|\\*|\\$|\\%[0-9]{2}|[0-9])\"\n",
            "\n",
            "    regex = re.compile(pattern)\n",
            "    tokens = [token for token in regex.findall(smi)]\n",
            "    smi_tokenized = ' '.join(tokens)\n",
            "    return smi_tokenized\n",
            "\n",
            "df_organic = pd.read_csv(\"csd_organic.csv\")\n",
            "df_organic = df_organic.dropna()\n",
            "\n",
            "tqdm.pandas()\n",
            "df_organic['smi_tokenized'] = df_organic['smiles'].progress_apply(tokenize_smiles)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Only prototype & pearson symbol"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic['tgt'] = df_organic['prototype'] + ': ' + df_organic['pearson']\n",
            "df_organic['tgt'] = [re.sub('([A-Z]):', r'\\1 :', tgt) for tgt in df_organic['tgt']]\n",
            "df_organic"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Only the spacegroup number"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 361607/361607 [22:48<00:00, 264.23it/s] \n"
               ]
            }
         ],
         "source": [
            "from ccdc import io\n",
            "\n",
            "def spacegroup_num_and_str_from_crystal(row, reader: io.EntryReader = None):\n",
            "    \n",
            "    if reader is None:\n",
            "        reader = io.EntryReader()\n",
            "\n",
            "    csd_entry = row['identifier']\n",
            "    entry = reader.entry(csd_entry)\n",
            "    crystal = entry.crystal\n",
            "    try:\n",
            "        spg_num = crystal.spacegroup_number_and_setting[0]\n",
            "        spg_str= crystal.spacegroup_symbol\n",
            "        row['spg_num'] = spg_num\n",
            "        row['spg_str'] = spg_str\n",
            "    except:\n",
            "        row['spg_num'] = None\n",
            "        row['spg_str'] = None\n",
            "    return row\n",
            "\n",
            "def spacegroup_str_from_crystal(csd_entry: str, reader: io.EntryReader = None):\n",
            "    \n",
            "    if reader is None:\n",
            "        reader = io.EntryReader()\n",
            "\n",
            "    entry = reader.entry(csd_entry)\n",
            "    crystal = entry.crystal\n",
            "    spg = crystal.spacegroup_symbol\n",
            "    return spg\n",
            "\n",
            "csd_reader = io.EntryReader()\n",
            "# df_head = df_organic.head().copy()\n",
            "# df_head.progress_apply(spacegroup_num_and_str_from_crystal, reader=csd_reader, axis=1)\n",
            "# df_organic['spg_num'] = df_organic['identifier'].progress_apply(spacegroup_num_from_crystal, reader=csd_reader)\n",
            "# df_organic['spg_str'] = df_organic['identifier'].progress_apply(spacegroup_str_from_crystal, reader=csd_reader)\n",
            "df_organic = df_organic.progress_apply(spacegroup_num_and_str_from_crystal, reader=csd_reader, axis=1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "identifier       0\n",
                     "smiles           0\n",
                     "wyckoff          0\n",
                     "smi_tokenized    0\n",
                     "spg_num          1\n",
                     "spg_str          1\n",
                     "dtype: int64"
                  ]
               },
               "execution_count": 19,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "df_organic.isna().sum()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic = df_organic.dropna()\n",
            "df_organic.spg_num = df_organic.spg_num.astype(int)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 25,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic.dropna().to_csv(\"csd_organic_tokenized.csv\", index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'Pb21a'"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "csd_reader = io.EntryReader()\n",
            "\n",
            "entry = csd_reader.entry('MTYHFB03')\n",
            "crystal = entry.crystal\n",
            "crystal.spacegroup_symbol"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "df_organic.to_csv(\"csd_organic_tokenized.csv\", index=False)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [],
         "source": [
            "from pathlib import Path\n",
            "\n",
            "def write_train_val_test(df, sub_folder, tgt_col: str = 'tgt'):\n",
            "\n",
            "    df = df.drop_duplicates(subset=['smiles'])\n",
            "    df_train_and_val = df.sample(frac=0.9, random_state=42)\n",
            "    df_test = df.drop(df_train_and_val.index)\n",
            "\n",
            "    df_train = df_train_and_val.sample(frac=0.9, random_state=42)\n",
            "    df_valid = df_train_and_val.drop(df_train.index)\n",
            "\n",
            "    data_path = f'/Users/williammccorkindale/ml_physics/smi2wyck/notebooks/data/{sub_folder}'\n",
            "    Path(data_path).mkdir(parents=True, exist_ok=True)\n",
            "    df_train.smi_tokenized.to_csv(f'{data_path}/src-train.csv', index=False, header=False)\n",
            "    df_train[tgt_col].to_csv(f'{data_path}/tgt-train.csv', index=False, header=False)\n",
            "\n",
            "    df_valid.smi_tokenized.to_csv(f'{data_path}/src-valid.csv', index=False, header=False)\n",
            "    df_valid[tgt_col].to_csv(f'{data_path}/tgt-valid.csv', index=False, header=False)\n",
            "\n",
            "    df_test.smi_tokenized.to_csv(f'{data_path}/src-test.csv', index=False, header=False)\n",
            "    df_test[tgt_col].to_csv(f'{data_path}/tgt-test.csv', index=False, header=False)\n",
            "    return\n",
            "\n",
            "write_train_val_test(df_organic, sub_folder='smi2spgnum', tgt_col='spg_num')\n",
            "write_train_val_test(df_organic, sub_folder='smi2spgstr', tgt_col='spg_str')"
         ]
      }
   ],
   "metadata": {
      "interpreter": {
         "hash": "fade0864c9a24203de3ed0faf9c71c898f3ed861f9409156898a7d5373bdd391"
      },
      "kernelspec": {
         "display_name": "Python 3.7.13 ('csd_env')",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.7.13"
      },
      "orig_nbformat": 4
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
